{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Transformers from scratch",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:42.934093Z",
          "iopub.execute_input": "2025-06-22T11:23:42.934425Z",
          "iopub.status.idle": "2025-06-22T11:23:42.938985Z",
          "shell.execute_reply.started": "2025-06-22T11:23:42.934403Z",
          "shell.execute_reply": "2025-06-22T11:23:42.938177Z"
        },
        "id": "4ZX8yyWWdl06"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:687bdefe-d1a2-4c47-afc1-9774ad1e3002.png)\n",
        "Lets divide the Transformers to some parts to let the coding easy\n",
        "\n",
        "1. Input block\n",
        "2. Encoder block\n",
        "3. Decoder block\n",
        "4. Output block\n",
        "   \n",
        "1. Input Block\n",
        "ðŸŽ¯ Purpose:\n",
        "Prepares the raw input tokens for processing by the encoder.\n",
        "\n",
        "ðŸ§© Components:\n",
        "Token Embedding: Converts tokens to dense vectors.\n",
        "\n",
        "Positional Encoding: Injects information about the token positions (since Transformers lack recurrence\n",
        "\n",
        "2.Encoder block\n",
        "\n",
        "Purpose:\n",
        "Encodes the input sequence into meaningful contextual representations.\n",
        "\n",
        "ðŸ§© Components:\n",
        "Multi-Head Self-Attention\n",
        "\n",
        "Residual Connection + Layer Normalization\n",
        "\n",
        "Feed Forward Network\n",
        "\n",
        "Residual Connection + Layer Normalization\n",
        "\n",
        "3. Decoder block\n",
        "\n",
        "ðŸŽ¯ Purpose:\n",
        "Generates the output sequence step-by-step, attending to both past outputs and encoder outputs.\n",
        "\n",
        "ðŸ§© Components:\n",
        "Masked Multi-Head Self-Attention\n",
        "\n",
        "Residual Connection + Layer Normalization\n",
        "\n",
        "Encoder-Decoder Attention\n",
        "\n",
        "Residual Connection + Layer Normalization\n",
        "\n",
        "Feed Forward Network\n",
        "\n",
        "Residual Connection + Layer Normalization\n",
        "\n",
        "4. Output block\n",
        "\n",
        "ðŸŽ¯ Purpose:\n",
        "Transforms decoder outputs into final probabilities over the vocabulary.\n",
        "\n",
        "ðŸ§© Components:\n",
        "Linear Projection Layer\n",
        "\n",
        "Softmax Activation"
      ],
      "metadata": {
        "id": "Y8s17_Z7dl09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word Embedding\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "    def forward(self, x):\n",
        "        out = self.embed(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:47.45931Z",
          "iopub.execute_input": "2025-06-22T11:23:47.459576Z",
          "iopub.status.idle": "2025-06-22T11:23:47.464528Z",
          "shell.execute_reply.started": "2025-06-22T11:23:47.45956Z",
          "shell.execute_reply": "2025-06-22T11:23:47.463614Z"
        },
        "id": "bybnTFMddl0_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For positional Encoding according the paper they used a specific formula to encode the position of the input data in the form of a trignometrical curve as below.\n",
        "\n",
        "![image.png](attachment:dfa0b013-af93-49c5-bdb0-e64302497729.png)\n",
        "![image.png](attachment:ce64ba77-ae89-4865-a739-be727d83766a.png)"
      ],
      "metadata": {
        "id": "0q8uRsuudl1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#positional Encoding\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self,max_seq_len,embed_model_dim):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_model_dim\n",
        "\n",
        "        pe = torch.zeros(max_seq_len,self.embed_dim)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0,self.embed_dim,2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/self.embed_dim)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/self.embed_dim)))\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * math.sqrt(self.embed_dim)\n",
        "        seq_len = x.size(1)\n",
        "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:48.514399Z",
          "iopub.execute_input": "2025-06-22T11:23:48.514688Z",
          "iopub.status.idle": "2025-06-22T11:23:48.521566Z",
          "shell.execute_reply.started": "2025-06-22T11:23:48.514666Z",
          "shell.execute_reply": "2025-06-22T11:23:48.520567Z"
        },
        "id": "HwxPQdCTdl1A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#MultiHead self Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim=512, n_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.single_head_dim = int(self.embed_dim / self.n_heads)\n",
        "        self.query_matrix = nn.Linear(self.single_head_dim , self.single_head_dim ,bias=False)\n",
        "        self.key_matrix = nn.Linear(self.single_head_dim  , self.single_head_dim, bias=False)\n",
        "        self.value_matrix = nn.Linear(self.single_head_dim ,self.single_head_dim , bias=False)\n",
        "        self.out = nn.Linear(self.n_heads*self.single_head_dim ,self.embed_dim)\n",
        "\n",
        "    def forward(self,key,query,value,mask=None):\n",
        "        batch_size = key.size(0)\n",
        "        seq_length = key.size(1)\n",
        "\n",
        "        seq_length_query = query.size(1)\n",
        "        key = key.view(batch_size, seq_length, self.n_heads, self.single_head_dim)\n",
        "        query = query.view(batch_size, seq_length_query, self.n_heads, self.single_head_dim)\n",
        "        value = value.view(batch_size, seq_length, self.n_heads, self.single_head_dim)\n",
        "\n",
        "        k = self.key_matrix(key)\n",
        "        q = self.query_matrix(query)\n",
        "        v = self.value_matrix(value)\n",
        "\n",
        "        q = q.transpose(1,2)\n",
        "        k = k.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "        k_adjusted = k.transpose(-1,-2)\n",
        "        product = torch.matmul(q, k_adjusted)\n",
        "        if mask is not None:\n",
        "             product = product.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "        product = product / math.sqrt(self.single_head_dim)\n",
        "        scores = torch.nn.functional.softmax(product, dim=-1)\n",
        "        scores = torch.matmul(scores, v)\n",
        "        concat = scores.transpose(1,2).contiguous().view(batch_size, seq_length_query, self.single_head_dim*self.n_heads)\n",
        "        output = self.out(concat)\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:49.967826Z",
          "iopub.execute_input": "2025-06-22T11:23:49.968517Z",
          "iopub.status.idle": "2025-06-22T11:23:49.978271Z",
          "shell.execute_reply.started": "2025-06-22T11:23:49.968492Z",
          "shell.execute_reply": "2025-06-22T11:23:49.977126Z"
        },
        "id": "iTon8eBndl1B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_heads)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "                          nn.Linear(embed_dim, expansion_factor*embed_dim),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(expansion_factor*embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self,key,query,value):\n",
        "        attention_out = self.attention(key,query,value)\n",
        "        attention_residual_out = attention_out + value\n",
        "        norm1_out = self.dropout1(self.norm1(attention_residual_out))\n",
        "\n",
        "        feed_fwd_out = self.feed_forward(norm1_out)\n",
        "        feed_fwd_residual_out = feed_fwd_out + norm1_out\n",
        "        norm2_out = self.dropout2(self.norm2(feed_fwd_residual_out))\n",
        "\n",
        "        return norm2_out\n",
        "\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, seq_len, vocab_size, embed_dim, num_layers=2, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.embedding_layer = Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoder = PositionalEmbedding(seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, expansion_factor, n_heads) for i in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed_out = self.embedding_layer(x)\n",
        "        out = self.positional_encoder(embed_out)\n",
        "        for layer in self.layers:\n",
        "            out = layer(out,out,out)\n",
        "\n",
        "        return out\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:51.549071Z",
          "iopub.execute_input": "2025-06-22T11:23:51.549386Z",
          "iopub.status.idle": "2025-06-22T11:23:51.557999Z",
          "shell.execute_reply.started": "2025-06-22T11:23:51.549366Z",
          "shell.execute_reply": "2025-06-22T11:23:51.557178Z"
        },
        "id": "s3LOOL2ldl1C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion_factor=4, n_heads=8):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_heads=8)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.transformer_block = TransformerBlock(embed_dim, expansion_factor, n_heads)\n",
        "\n",
        "\n",
        "    def forward(self, key, query, x,mask):\n",
        "        attention = self.attention(x,x,x,mask=mask)\n",
        "        value = self.dropout(self.norm(attention + x))\n",
        "\n",
        "        out = self.transformer_block(key, query, value)\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, target_vocab_size, embed_dim, seq_len, num_layers=2, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.word_embedding = nn.Embedding(target_vocab_size, embed_dim)\n",
        "        self.position_embedding = PositionalEmbedding(seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_dim, expansion_factor=4, n_heads=8)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, enc_out, mask):\n",
        "        x = self.word_embedding(x)\n",
        "        x = self.position_embedding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(enc_out, x, enc_out, mask)\n",
        "\n",
        "        out = torch.nn.functional.softmax(self.fc_out(x))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:53.403217Z",
          "iopub.execute_input": "2025-06-22T11:23:53.40386Z",
          "iopub.status.idle": "2025-06-22T11:23:53.412697Z",
          "shell.execute_reply.started": "2025-06-22T11:23:53.403821Z",
          "shell.execute_reply": "2025-06-22T11:23:53.411705Z"
        },
        "id": "0CIBoy_Fdl1D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, src_vocab_size, target_vocab_size, seq_length,num_layers=2, expansion_factor=4, n_heads=8):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "        self.encoder = TransformerEncoder(seq_length, src_vocab_size, embed_dim, num_layers=num_layers, expansion_factor=expansion_factor, n_heads=n_heads)\n",
        "        self.decoder = TransformerDecoder(target_vocab_size, embed_dim, seq_length, num_layers=num_layers, expansion_factor=expansion_factor, n_heads=n_heads)\n",
        "\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        batch_size, trg_len = trg.shape\n",
        "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
        "            batch_size, 1, trg_len, trg_len\n",
        "        )\n",
        "        return trg_mask\n",
        "\n",
        "    def decode(self,src,trg):\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_out = self.encoder(src)\n",
        "        out_labels = []\n",
        "        batch_size,seq_len = src.shape[0],src.shape[1]\n",
        "        out = trg\n",
        "        for i in range(seq_len):\n",
        "            out = self.decoder(out,enc_out,trg_mask)\n",
        "            out = out[:,-1,:]\n",
        "\n",
        "            out = out.argmax(-1)\n",
        "            out_labels.append(out.item())\n",
        "            out = torch.unsqueeze(out,axis=0)\n",
        "\n",
        "\n",
        "        return out_labels\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_out = self.encoder(src)\n",
        "\n",
        "        outputs = self.decoder(trg, enc_out, trg_mask)\n",
        "        return outputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:54.674969Z",
          "iopub.execute_input": "2025-06-22T11:23:54.675247Z",
          "iopub.status.idle": "2025-06-22T11:23:54.683216Z",
          "shell.execute_reply.started": "2025-06-22T11:23:54.675229Z",
          "shell.execute_reply": "2025-06-22T11:23:54.682239Z"
        },
        "id": "iDJ43DfOdl1E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = 11\n",
        "target_vocab_size = 11\n",
        "num_layers = 6\n",
        "seq_length= 12\n",
        "\n",
        "\n",
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1],\n",
        "                    [0, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, 1]])\n",
        "target = torch.tensor([[0, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, 1],\n",
        "                       [0, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, 1]])\n",
        "\n",
        "print(src.shape,target.shape)\n",
        "model = Transformer(embed_dim=512, src_vocab_size=src_vocab_size,\n",
        "                    target_vocab_size=target_vocab_size, seq_length=seq_length,\n",
        "                    num_layers=num_layers, expansion_factor=4, n_heads=8)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:55.674152Z",
          "iopub.execute_input": "2025-06-22T11:23:55.674617Z",
          "iopub.status.idle": "2025-06-22T11:23:56.170048Z",
          "shell.execute_reply.started": "2025-06-22T11:23:55.674591Z",
          "shell.execute_reply": "2025-06-22T11:23:56.16912Z"
        },
        "id": "3zhh-fTqdl1F",
        "outputId": "fe4eefbf-97d8-45bd-a693-90369be38924"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([2, 12]) torch.Size([2, 12])\n",
          "output_type": "stream"
        },
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Transformer(\n  (encoder): TransformerEncoder(\n    (embedding_layer): Embedding(\n      (embed): Embedding(11, 512)\n    )\n    (positional_encoder): PositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadAttention(\n          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (feed_forward): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): ReLU()\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (dropout1): Dropout(p=0.2, inplace=False)\n        (dropout2): Dropout(p=0.2, inplace=False)\n      )\n    )\n  )\n  (decoder): TransformerDecoder(\n    (word_embedding): Embedding(11, 512)\n    (position_embedding): PositionalEmbedding()\n    (layers): ModuleList(\n      (0-5): 6 x DecoderBlock(\n        (attention): MultiHeadAttention(\n          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.2, inplace=False)\n        (transformer_block): TransformerBlock(\n          (attention): MultiHeadAttention(\n            (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n            (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n            (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n            (out): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (feed_forward): Sequential(\n            (0): Linear(in_features=512, out_features=2048, bias=True)\n            (1): ReLU()\n            (2): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (dropout1): Dropout(p=0.2, inplace=False)\n          (dropout2): Dropout(p=0.2, inplace=False)\n        )\n      )\n    )\n    (fc_out): Linear(in_features=512, out_features=11, bias=True)\n    (dropout): Dropout(p=0.2, inplace=False)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(src, target)\n",
        "out.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:23:56.731307Z",
          "iopub.execute_input": "2025-06-22T11:23:56.732052Z",
          "iopub.status.idle": "2025-06-22T11:23:56.852249Z",
          "shell.execute_reply.started": "2025-06-22T11:23:56.73202Z",
          "shell.execute_reply": "2025-06-22T11:23:56.851388Z"
        },
        "id": "M4tuJ6Kkdl1H",
        "outputId": "33e6c146-92c1-47e8-82b4-958696d42fba"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/3781720743.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  out = torch.nn.functional.softmax(self.fc_out(x))\n",
          "output_type": "stream"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([2, 12, 11])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(embed_dim=512, src_vocab_size=src_vocab_size,\n",
        "                    target_vocab_size=target_vocab_size, seq_length=seq_length,\n",
        "                    num_layers=num_layers, expansion_factor=4, n_heads=8)\n",
        "\n",
        "\n",
        "\n",
        "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1]])\n",
        "trg = torch.tensor([[0]])\n",
        "print(src.shape,trg.shape)\n",
        "out = model.decode(src, trg)\n",
        "out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-22T11:24:13.402063Z",
          "iopub.execute_input": "2025-06-22T11:24:13.402343Z",
          "iopub.status.idle": "2025-06-22T11:24:14.083735Z",
          "shell.execute_reply.started": "2025-06-22T11:24:13.402324Z",
          "shell.execute_reply": "2025-06-22T11:24:14.082918Z"
        },
        "id": "QmY4_887dl1H",
        "outputId": "944b9c8d-0904-42fb-fda2-39b20383690b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([1, 12]) torch.Size([1, 1])\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/3781720743.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  out = torch.nn.functional.softmax(self.fc_out(x))\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "TT15iaPVdl1H"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}